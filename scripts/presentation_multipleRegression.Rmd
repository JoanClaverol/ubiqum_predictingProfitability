---
title: "Multiple regression in R"
author: "Joan Claverol"
date: "31 de marzo de 2019"
output: 
  ioslides_presentation:
    widescreen: true
    smaller: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r loading libraries and dataset, message=FALSE, warning=F}
if(require("pacman")=="FALSE"){
  install.packages("pacman")
} 

pacman::p_load(corrplot, tidyverse, caret, dunn.test, Hmisc,xtable, htmlTable, 
               knitr, kableExtra, RColorBrewer, e1071, FNN, scales,
               tibble, modelr, magrittr, VIM, fastDummies, plotly)

ex_prod <- read_csv("../data/existingproductattributes2017.2.csv")
NwProd <- read_csv("../data/newproductattributes2017.2.csv")
```

## Task overview

**BUSINESS QUESTION:** Which are the top 5 products that are going to be more profitable for the company?

What data do we have? 

New product attributes and existing product attributes.

- Predicting sales of four different product types: PC, Laptops, Netbooks and Smartphones
- Assessing the impact services reviews and customer reviews have on sales of different product types

## Index

1. Data cleaning

2. Data exploration

3. Pre-process: feature selection (correlation matrix) & feature engineering

4. Modalization: linear regresion, KNN, SVM, Random forest, GBM

5. Error analysis

## Data cleaning

Transformation to factor:

```{r transformation to factors, echo=TRUE}
fact_var <- c("ProductType","ProductNum")
ex_prod[,fact_var] <- apply(ex_prod[,fact_var], 2, as.factor)
```

Giving names to the rows: 

```{r changing row names with product number, echo=TRUE}

ex_prod <- tibble::column_to_rownames(.data = ex_prod,
                                     var = "ProductNum")
ex_prod$ProductNum <- NULL
```

## Data cleaning: missing values with VIM {.flexbox .vcenter}

```{r looking for NAs, message=F, warning=F}
aggr(ex_prod, col=c('lightblue','red'), numbers=TRUE, sortVars=TRUE, 
     labels=names(data), cex.axis=.7,  gap=3, only.miss = F, 
     ylab=c("Histogram of missing data","Pattern"),plot = T)
# change blue color
ex_prod$BestSellersRank <- NULL
```

## 1st data expl.: Blackwell business {.flexbox .vcenter}

```{r business overview, warning=F}
# Is the volume related to the categories?

ex_prod %>%
  group_by(ProductType) %>%
  summarise(Total_Volume = sum(Volume)) %>%
  arrange(desc(Total_Volume)) -> Volume_category

# Number of products by category
ex_prod %>%
  group_by(ProductType) %>%
  summarise(Number_Products = n()) %>%
  arrange(desc(Number_Products)) -> NumProd_category

# Profit per category
ex_prod %>%
  group_by(ProductType) %>%
  summarise(Mean_Profit_Perc = round(mean(ProfitMargin),2)) %>%
  arrange(desc(Mean_Profit_Perc)) -> Profit_category

# Create a graph to understand Blackwell's business
Profit_category %>%
  left_join(NumProd_category, by = 'ProductType') %>%
  left_join(Volume_category, by = 'ProductType') %>%
  mutate(Total_Profits = Mean_Profit_Perc*Total_Volume, 
         Total_Profits_Dol = paste(round((Total_Profits), 0),"$")) %>% 
  arrange(Total_Profits) %>% 
  ggplot(aes(x = reorder(ProductType, Total_Profits))) +
    geom_col(aes(y = -Total_Profits), fill = "gold") +
    geom_col(aes(y = Total_Volume), fill = "dodgerblue3") +
    coord_flip() +
    scale_y_continuous(limits = c(-6000,27000), labels = NULL) +
    geom_label(aes(x = ProductType, y = -Total_Profits, 
                   label = Total_Profits_Dol),
               hjust = 1, 
               vjust = 0.4, 
               colour = "goldenrod3", 
               fill = NA, 
               label.size = NA, 
               size = 3.5) +
    geom_label(aes(x = ProductType, y = Total_Volume, 
                   label = round(Total_Volume, 0)),
               hjust = 0, 
               vjust = 0.4, 
               colour = "dodgerblue4", 
               fill = NA, 
               label.size = NA, 
               size = 3.5) +
    labs(title = "Total Profits ($) vs Total Volume (items)") +
    theme(legend.position = "bottom", 
          legend.title = element_blank(), 
          plot.title = element_text(hjust = 0.5), 
          plot.subtitle = element_text(hjust = 0.5)) + theme_void() -> p1
p1 + theme(axis.title.x = element_blank(), 
           axis.title.y = element_blank(), 
           axis.text.y = element_text()) +
  geom_label(aes(x = "Printer", y = 10000, 
                 label = "The 45% of the sales comes from\naccessories, but they only\nrespresents the 15% of the total\nprofit"),
             hjust = 0, 
             vjust = 0.5, 
             lineheight = 0.8,
             colour = "dodgerblue4", 
             fill = "white", 
             label.size = NA, 
             size = 4.5) +
  geom_label(aes(x = "Laptop", y = 10000, 
                 label = "Extended warranty generates the\n46% of the total profit, and\nrepresents the 18% of the sales"),
             hjust = 0, 
             vjust = 0.5, 
             lineheight = 0.8,
             colour = "goldenrod3", 
             fill = "white", 
             label.size = NA, 
             size = 4.5)
  
```

## 1st data expl.: Volume distribution {.flexbox .vcenter}

```{r boxplot to understand the distribution of the volume, warning=FALSE, message=FALSE}
# creating a function to find outliers
is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

# creating the graphs
ex_prod %>% 
  rownames_to_column(var = "productNum") %>% 
  group_by(ProductType) %>%
  mutate(outlier=ifelse(is_outlier(Volume),as.numeric(productNum),
                        as.numeric(NA))) %>%
  ggplot(aes(ProductType, Volume)) + 
    geom_boxplot(outlier.color = "red", col = "dodgerblue3") +
    geom_label(aes(label = outlier), hjust = 0, 
               vjust = 0, check_overlap = TRUE,
               colour = "red", 
               fill = NA, 
               label.size = NA, 
               size = 3.5) +
    geom_label(aes(x = "Laptop", y = 10000, 
                   label = "Accessories: median very close to 0, and the product\n150 is an anomaly."), 
               label.size = NA, 
               size = 4.5, 
               colour = "#555555", 
               hjust = 0, 
               vjust = 0.5, 
               lineheight = 0.8) +
    geom_label(aes(x = "Laptop", y = 8000, 
                   label = "Extended warranty: the range is very gathered and\nthere are two products, 132 and 133, close to 0."), 
               label.size = NA, 
               size = 4.5, 
               colour = "#555555", 
               hjust = 0, 
               vjust = 0.5, 
               lineheight = 0.8) +
    geom_label(aes(x = "Laptop", y = 6000, 
                   label = "GameConsole: the highest sells in the company and\nmore stable."), 
               label.size = NA, 
               size = 4.5, 
               colour = "#555555", 
               hjust = 0, 
               vjust = 0.5, 
               lineheight = 0.8) +
    labs(title = "Volume distribution in relation to product type") +
    theme_classic() + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 11), 
          axis.text.y = element_text(size = 11), legend.position = "none",
          axis.title.x = element_blank(), axis.title.y = element_blank())
```

## 1st modalisation: linear regression

```{r 1st model creatin, warning=F, message=F, echo=T}
# train and test
train_id <- createDataPartition(y = ex_prod$Volume, p = 0.80, list = F)
train <- ex_prod[train_id,]
test <- ex_prod[-train_id,]

# create linear regression model
mod_lm <- lm(formula = Volume ~ ., data = train)

# model performance
postResample(pred = predict(object = mod_lm, newdata = test),
             obs = test$Volume)
```

Main predictors: 

1. 5 stars
2. Product type: Game console

## 2nd pre-process: feature selection {.flexbox .vcenter}



```{r}
# Dummy variables 
ex_prod_dummy <- ex_prod %>% 
  fastDummies::dummy_columns(remove_first_dummy = FALSE) %>% 
  select(-ProductType, -ShippingWeight, -ProductDepth,
         -ProductWidth, -ProductHeight, -ProductType_Accessories,
         -ProductType_Software, -ProductType_Display, -ProductType_Printer,
         -ProductType_PrinterSupplies, -ProductType_ExtendedWarranty,
         -ProductType_Tablet, -ProductType_GameConsole) %>% 
  rename(PC = ProductType_PC, 
         Laptop = ProductType_Laptop,
         Netb = ProductType_Netbook,
         Smart_Ph = ProductType_Smartphone, 
         x5 = x5StarReviews, 
         x4 = x4StarReviews,
         x3 = x3StarReviews, 
         x2 = x2StarReviews, 
         x1 = x1StarReviews, 
         Pos_Ser = PositiveServiceReview, 
         Neg_Ser = NegativeServiceReview,
         Recomend = Recommendproduct,
         Profit_M = ProfitMargin,
         Vol = Volume)
rownames(ex_prod_dummy) <- rownames(ex_prod)


# Correlation plot
ex_prod_corr <- cor(ex_prod_dummy)
corrplot(ex_prod_corr, method = "pie", 
         type = "lower", order = "hclust", 
         col = brewer.pal(n = 8, name = "RdBu"),
         number.cex = 0.9, number.digits = 2, 
         tl.cex = 1.2, tl.srt = 1, tl.col = "black")
```

## 2nd modalisation: linear regression {.bigger}

```{r 2nd model creation, warning=FALSE, message=FALSE}
# creating trainin and testing with the features selected
set.seed(123)
train_id <- createDataPartition(y = ex_prod_dummy$Vol,
                                p = 0.80,
                                list = F)
train <- ex_prod_dummy[train_id,]
test <- ex_prod_dummy[-train_id,]

# model creation
mod_2lm <- lm(formula = Vol ~., data = train)

# metrics
postResample(pred = predict(object = mod_2lm, newdata = test),
             obs = test$Vol)
```

Main predictors: 

1. 5 stars
2. Product type: PC
3. Price

The model is overfitted again. 

## 3rd pre-process: outlier detection in stars {.flexbox .vcenter}

```{r plot the stars volume relation, warning=F, message=F}
ex_prod_dummy %>%
  rownames_to_column(var = "product_num") %>%
  gather(key = "star_type", value = "num_stars", x5, x4, x3, x2, x1) %>% 
  ggplot(aes(x = num_stars, y = Vol, color = star_type)) +
    geom_point() +
    geom_smooth(se = F, size = 0.15) +
    theme_classic() +
    theme(axis.text.y = element_text(),
          axis.text.x = element_text(), 
          legend.title = element_blank()) +
    labs(title = "Total sales vs type of star", 
         y = "Volume", x = "Number of stars") -> stars_plot
ggplotly(stars_plot) %>% 
  layout(annotations = list(x = 2801, y = 11204, text = "Prod. 150", 
                            showarrow = TRUE, arrowcolor = "#555555",
                            arrowsize = 0.3, font = list(size = 10))) %>% 
  layout(annotations = list(x = 1759, y = 7036, text = "Prod. 198", 
                            showarrow = TRUE, arrowcolor = "#555555",
                            arrowsize = 0.3, font = list(size = 10), 
                            ax= 0, ay = -20)) %>%
  layout(annotations = list(x = 1654, y = 2052, text = "Prod. 123", 
                            showarrow = TRUE, arrowcolor = "#555555",
                            arrowsize = 0.3, font = list(size = 10),
                            ax = 10, ay = 20))
  
```

```{r outlier extraction}
ex_prod_dummy %<>%
  rownames_to_column(var = "product_num") %>% 
  filter(!(product_num %in% c("123","198","150")))
```

## 3rd pre-process: feature engineering {.flexbox .vcenter}

```{r volumen total stars relation, message=F, warning=F}
# 
ex_prod_dummy %<>% 
  rowwise() %>% 
  mutate(total_stars = sum(x5, x4, x3, x2, x1)) 

ex_prod_dummy %>% 
  ggplot(aes(x = total_stars, y = Vol)) +
    geom_point(color = "dodgerblue4") +
    geom_smooth(alpha=0.3, size=0, span=0.5, se = F) +
    geom_label(aes(x = 650, y = 900, 
                   label = "There is a clear positive correlation\nbetween the total number of reviews\na product has with the number of sales"),
             hjust = 0, 
             vjust = 0.5, 
             lineheight = 0.8,
             colour = "#555555", 
             fill = "white", 
             label.size = NA, 
             size = 4.5 ) +
    theme_classic() +
    theme(axis.text.y = element_text(),
          axis.text.x = element_text(), 
          legend.title = element_blank()) +
    labs(title = "Total sales vs total number of reviews by product", 
         y = "Volume", x = "total number of reviews")
```

## 3rd modalisation: linear regression

```{r 3rd model with linear regression}
ex_prod_dummy %<>% 
  select(-x5, -x4, -x3, -x2, -x1, -Profit_M, -Price) %>% 
  column_to_rownames(var = "product_num")

# creating trainin and testing with the features selected
set.seed(123)
train_id <- createDataPartition(y = ex_prod_dummy$Vol,
                                p = 0.80,
                                list = F)
train <- ex_prod_dummy[train_id,]
test <- ex_prod_dummy[-train_id,]

# model creation
mod_3lm <- lm(formula = Vol ~., data = train)

# metrics
postResample(pred = predict(object = mod_3lm, newdata = test),
             obs = test$Vol)
```

| Variables used            | Main predictors         |
| ------------------------- |-------------------------|
| - Total number of stars   | - Total number of stars |
| - Positive service        | - Positive service      |
| - Negative serice         | - Negative service      |
| - Recommended product     | - Recommended product   |
| - PC                      |                         |
| - Laptop                  |                         |
| - Netbook                 |                         |
| - Smart Phone             |                         |

## 3rd error check: errors in all the ex. prod {.flexbox .vcenter}

```{r error visualization 3rd model, warning=FALSE}
# adding product number to datasets and creating one only with categories
ex_prod$product_num <- rownames(ex_prod)
ex_prod_dummy$product_num <- rownames(ex_prod_dummy)
product_cat <- ex_prod %>% select(product_num, ProductType)

# define the treshold of the errors and relevant categories
treshold <- 80
rel_categories <- c("PC","Laptop","Smartphone","Netbooks")

# looking at the metrics of the relevant categories
ex_prod_dummy %<>%
  left_join(y = product_cat, by = "product_num") %>% 
  add_predictions(model = mod_3lm, var = "pred") %>% 
  add_residuals(model = mod_3lm, var = "resid")

ex_prod_dummy %>% 
  dplyr::filter(ProductType %in% rel_categories) -> ex_prod_filt

metrics_rel_prod <- postResample(pred = ex_prod_filt$pred, obs = ex_prod_filt$Vol)
#        RMSE    Rsquared         MAE 
# 117.8325360   0.9455967  82.2058960 

# error plot
ex_prod_dummy %>% 
  ggplot(aes(x = pred, y = Vol)) +
    geom_point(aes(color = (ProductType %in% rel_categories))) + 
    geom_abline(intercept = 0, slope = 1, color = "darkgray") +
    geom_label(aes(label = if_else(abs(resid)>treshold & 
                              ProductType %in% rel_categories, 
                              product_num, NULL)),
               hjust = 0, 
               vjust = 0.4, 
               colour = "red2", 
               fill = NA, 
               label.size = NA, 
               size = 3.5) +
    geom_label(aes(x = 1230, y = 700,
                   label = paste0("The metrics for the relevant product types are:\n   - RMSE: ",round(metrics_rel_prod[[1]],3),"\n   - Rsquared: ",round(metrics_rel_prod[[2]],3),"\n   - MAE: ",round(metrics_rel_prod[[3]],3),"\n\nThe errors of the points with the product\nnumber are higher than +/-",treshold," items.")),
               label.size = NA,
               size = 4.5,
               colour = "red2",
               hjust = 0,
               vjust = 0.5,
               lineheight = 0.8) +
    labs(title = "Error visualizations 3rd model (lm)",
         x = "Predicted volume",
         y = "Volume") +
    scale_color_manual(values = c("grey","red")) +
    theme_classic() +
    theme(axis.text.y = element_text(),
          axis.text.x = element_text(), 
          legend.title = element_blank(), 
          legend.position = "none") -> error_plot_mod3
error_plot_mod3
```

## 4th exploration: recommandation variable {.flexbox .vcenter}

```{r recommendation variable exploration, warning=F, message=F}
ex_prod_dummy %>% 
  group_by(as.factor(Recomend)) %>% 
  mutate(outlier=ifelse(is_outlier(Vol),as.numeric(product_num),
                        as.numeric(NA))) %>%
  ggplot(aes(x = as.factor(Recomend), y = Vol)) + 
    geom_boxplot(outlier.color = "red", col = "dodgerblue3") +
    geom_label(aes(label = outlier), hjust = 0, 
               vjust = 0, check_overlap = TRUE,
               colour = "red", 
               fill = NA, 
               label.size = NA, 
               size = 3.5) +
    geom_label(aes(x = "0.1", y = 2000, 
                   label = "There is an increase of the range related to the increment\nof the % recommendation, but the dispersion is too big."), 
               label.size = NA, 
               size = 3.5, 
               colour = "#555555", 
               hjust = 0, 
               vjust = 0.5, 
               lineheight = 0.8) +
    theme_classic() +
    labs(title = "Distribution of the volume for each recommendation",
         x = "% of product recommendation", y = "Volume")
```

## 4th pre-process: repeated observations {.flexbox .vcenter}

```{r identifying repeated rows, warning=F, message=F}
kable(ex_prod_dummy %>% 
  select(product_num, ProductType, total_stars, Pos_Ser, Neg_Ser, Recomend, Vol) %>% 
  filter(ProductType %in% c("ExtendedWarranty")), format = "html") %>% 
  kable_styling(bootstrap_options = c("hover"), 
                full_width = T, position = "center", fixed_thead = T) %>% 
  row_spec(3:10, bold = T, background = "#f0f5f0")

ex_prod_dummy %<>% 
  dplyr::distinct(ProductType, total_stars, Pos_Ser, Neg_Ser, Recomend, Vol, 
                  .keep_all = TRUE)
```

## 4th feature engineering: pos. and neg. service {.flexbox .vcenter}

```{r negative and positive service vs volume, warning=F, message=F}
ex_prod_dummy %>% 
  gather(key = "service_type", value = "service_quantity", Pos_Ser, Neg_Ser) %>% 
  ggplot(aes(y = Vol, x = service_quantity, color = service_type)) +
    geom_point(alpha = 0.35) +
    geom_smooth(se = F, size = 0.15) +
    labs(title = "Total volume vs the total quantity of services", 
         x = "Number of services", y = "Volume") +
    geom_label(aes(x = 52, y = 890, label = "Positive\nservice"), 
               label.size = NA,
               size = 4,
               colour = "darkgreen",
               hjust = 0,
               vjust = 0,
               lineheight = 0.8) +
    geom_label(aes(x = 300, y = 525, label = "Negative\nservice"), 
               label.size = NA,
               size = 4,
               colour = "darkred",
               lineheight = 0.8) +
    geom_curve(aes(xend = 35, yend = 1270, x = 100, y = 1450), 
               colour = "darkred",
               size = 0.5, 
               curvature = -0.2, 
               arrow = arrow(length = unit(0.03, "npc"))) +
    geom_label(aes(x = 100, y = 1400, label = "When the number of services starts\nto surpass 40, then the sales start to\ndecrease."),
               label.size = NA,
               size = 4,
               colour = "darkred",
               hjust = 0,
               vjust = 0,
               lineheight = 0.8) +
    geom_label(aes(label = if_else(service_type %in% "Pos_Ser" & 
                                     service_quantity > 40 &
                                     Vol < 1000, ProductType, NULL)), 
               label.size = NA,
               size = 4,
               colour = "darkgreen",
               hjust = -0.5,
               vjust = 1.2,
               lineheight = 0, 
               alpha = 0.3) +
    scale_color_manual(values = c("darkgreen","darkred"), 
                       labels = c("Positive service", "Negative\nservice")) +
    theme_classic() +
    theme(axis.text.y = element_text(),
          axis.text.x = element_text(), 
          legend.position = "none")

# taking out the outliers in positive service review
ex_prod_dummy %<>%
  dplyr::filter(!(product_num %in% c("167")))
```

## 4th modalisation: linear regression

```{r 4th modlaization, echo=T}
ex_prod_4mod <- ex_prod_dummy %>% 
  dplyr::select(Pos_Ser, Neg_Ser, Recomend, PC, Laptop, 
                Netb, Smart_Ph, total_stars, Vol)

# creating trainin and testing with the features selected
set.seed(123)
train_id <- createDataPartition(y = ex_prod_4mod$Vol,
                                p = 0.80,
                                list = F)
train <- ex_prod_4mod[train_id,]
test <- ex_prod_4mod[-train_id,]

# model creation
mod_4lm <- lm(formula = Vol ~., data = train)

# metrics
postResample(pred = predict(object = mod_4lm, newdata = test),
             obs = test$Vol)
```

The model has decrease the performance. Let's see how is performing to the categories we are interested. 

## 4th error check: error visualization {.flexbox .vcenter}

```{r 4th error check, warning=F, message=F}
# looking at the metrics of the relevant categories
ex_prod_dummy %<>%
  add_predictions(model = mod_3lm, var = "pred") %>% 
  add_residuals(model = mod_3lm, var = "resid")

ex_prod_dummy %>% 
  dplyr::filter(ProductType %in% rel_categories) -> ex_prod_filt

metrics_rel_prod <- postResample(pred = ex_prod_filt$pred, obs = ex_prod_filt$Vol)

# error plot
ex_prod_dummy %>% 
  ggplot(aes(x = pred, y = Vol)) +
    geom_point(aes(color = (ProductType %in% rel_categories))) + 
    geom_abline(intercept = 0, slope = 1, color = "darkgray") +
    geom_label(aes(label = if_else(abs(resid)>treshold & 
                              ProductType %in% rel_categories, 
                              product_num, NULL)),
               hjust = 0, 
               vjust = 0.4, 
               colour = "red2", 
               fill = NA, 
               label.size = NA, 
               size = 3.5) +
    geom_label(aes(x = 1230, y = 700,
                   label = paste0("The metrics for the relevant product types are:\n   - RMSE: ",round(metrics_rel_prod[[1]],3),"\n   - Rsquared: ",round(metrics_rel_prod[[2]],3),"\n   - MAE: ",round(metrics_rel_prod[[3]],3),"\n\nMy model has NOT improved.")),
               label.size = NA,
               size = 4.5,
               colour = "red2",
               hjust = 0,
               vjust = 0.5,
               lineheight = 0.8) +
    labs(title = "Error visualizations 4th model (lm)",
         x = "Predicted volume",
         y = "Volume") +
    scale_color_manual(values = c("grey","red")) +
    theme_classic() +
    theme(axis.text.y = element_text(),
          axis.text.x = element_text(), 
          legend.title = element_blank(), 
          legend.position = "none") -> error_plot_mod4
error_plot_mod4
```

## 5th modalization: k-Nearest neighbours

```{r preparing data fpr modalization with knn}
# scaling variables
ex_prod_dummy$Pos_Ser_sc <- rescale(ex_prod_dummy$Pos_Ser)
ex_prod_dummy$Neg_Ser_sc <- rescale(ex_prod_dummy$Neg_Ser)
ex_prod_dummy$Recomend_sc <- rescale(ex_prod_dummy$Recomend)
ex_prod_dummy$total_stars_sc <- rescale(ex_prod_dummy$total_stars)

#vector con nombres de las variables escaladas
sc_var <- c("Pos_Ser_sc","Neg_Ser_sc","Recomend_sc","total_stars_sc")

# creating training and testing 
set.seed(123)
train_id <- createDataPartition(y = ex_prod_dummy$Vol,
                                p = 0.8, 
                                list = F)
train <- ex_prod_dummy[train_id,]
test <- ex_prod_dummy[-train_id,]
```

```{r first modalization with knn, echo=TRUE}
# modalization with knn
mod_5knn <- knn.reg(train[,sc_var], # predictores que usaremos para predecir 
                    test[,sc_var], # validadores, los predictores que queremos usar para validar
                    train$Vol, # salida que tiene que dar en el conjunto de entrenamiento
                    k = 1, # número de vecinos
                    algorithm = "brute") # algoritmos que se pueden usar

# checking the metrics 
postResample(pred = mod_5knn$pred, obs = test$Vol)
```

## 5th modalisation: KNN choosing the best k {.flexbox .vcenter}

```{r selecting the best k for knn}
rdacb.knn.reg <- function(tr_predictors, val_predictors, 
                          tr_target, val_target, k){
  library(FNN)
  res <- knn.reg(tr_predictors, val_predictors,
                 tr_target, k, algorithm = "brute")
  rmserror <- sqrt(mean((val_target - res$pred)^2))
  # cat(paste("RMSE para k = ", toString(k), ": ", rmserror, "\n", sep = ""))
  rmserror
}

radcb.knn.reg.multi <- function(tr_predictors, val_predictors,
                                tr_target, val_target, start_k, end_k){
  rms_errors <- vector()
  for(k in start_k:end_k){
    rms_error <- rdacb.knn.reg(tr_predictors, val_predictors, 
                               tr_target, val_target, k)
    rms_errors <- c(rms_errors, rms_error)
  }
  plot(rms_errors, type = "o", xlab = "k", ylab = "RMSE")
}

radcb.knn.reg.multi(train[,sc_var], test[,sc_var], train$Vol, test$Vol, 1, 15)

# selecting 11 k to be more generalised 
mod_5knn <- knn.reg(train[,sc_var], # predictores que usaremos para predecir 
                    test[,sc_var], # validadores, los predictores que queremos usar para validar
                    train$Vol, # salida que tiene que dar en el conjunto de entrenamiento
                    k = 11, # número de vecinos
                    algorithm = "brute") # algoritmos que se pueden usar
postResample(pred = mod_5knn$pred, obs = test$Vol)
```

